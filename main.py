"""
å¤šæä¾›å•† LLM å®¢æˆ·ç«¯ - ä¸»åº”ç”¨æ–‡ä»¶
é‡æ„ç‰ˆæœ¬ï¼Œæ”¯æŒå¤šä¸ªAIæä¾›å•†å’Œæ›´å¥½çš„æ¨¡å—åŒ–
"""

import gradio as gr

from api_service import api_service
from chat_manager import ChatManager, MessageProcessor
from config import (
    get_supported_models, DEFAULT_MODEL, SERVER_HOST, SERVER_PORT,
    CHATBOT_HEIGHT, MAX_INPUT_LINES, check_api_key
)


class LLMClient:
    """LLMå®¢æˆ·ç«¯ä¸»ç±»"""

    def __init__(self):
        self.chat_manager = ChatManager()
        self.message_processor = MessageProcessor()

    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(
                title="Cerebras LLM å®¢æˆ·ç«¯",
                theme=gr.themes.Soft(),
                css=self._get_custom_css()
        ) as demo:
            # æ ‡é¢˜å’Œæè¿°
            gr.Markdown(self._get_header_markdown())

            # æ§åˆ¶é¢æ¿
            with gr.Row():
                with gr.Column(scale=1, elem_classes="control-panel"):
                    model_dropdown = gr.Dropdown(
                        choices=get_supported_models(),
                        value=DEFAULT_MODEL,
                        label="é€‰æ‹©æ¨¡å‹",
                        info="é€‰æ‹©è¦ä½¿ç”¨çš„LLMæ¨¡å‹"
                    )

                    # çŠ¶æ€é¢æ¿
                    status_panel = gr.Textbox(
                        label="ç³»ç»ŸçŠ¶æ€",
                        value=self._get_initial_status(),
                        interactive=False,
                        max_lines=3,
                        show_copy_button=False
                    )

                with gr.Column(scale=3, elem_classes="chat-area"):
                    # èŠå¤©ç•Œé¢ - ä½¿ç”¨æ–°çš„messagesæ ¼å¼
                    chatbot = gr.Chatbot(
                        label="å¯¹è¯ç•Œé¢",
                        height=CHATBOT_HEIGHT,
                        type="messages",  # ä¿®å¤è­¦å‘Šï¼Œä½¿ç”¨æ–°çš„messagesæ ¼å¼
                        show_copy_button=True,
                        avatar_images=(
                            "https://cdn-icons-png.flaticon.com/512/3135/3135715.png",  # ç”¨æˆ·å¤´åƒ
                            "https://cdn-icons-png.flaticon.com/512/4712/4712035.png"  # AIå¤´åƒ
                        )
                    )

            # è¾“å…¥åŒºåŸŸ
            with gr.Row():
                msg = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                    scale=4,
                    max_lines=MAX_INPUT_LINES,
                    show_copy_button=False
                )
                submit_btn = gr.Button("å‘é€", variant="primary", scale=1, size="lg")

            # æ§åˆ¶æŒ‰é’®
            with gr.Row():
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", variant="secondary")
                export_btn = gr.Button("ğŸ“¥ å¯¼å‡ºå¯¹è¯", variant="secondary")

            # ç»‘å®šäº‹ä»¶
            self._setup_event_handlers(
                demo, msg, chatbot, model_dropdown,
                submit_btn, clear_btn, export_btn, status_panel
            )

        return demo

    def _get_custom_css(self):
        """è·å–è‡ªå®šä¹‰CSSæ ·å¼"""
        return """
        .gradio-container {
            width: 100% !important;
            max-width: none !important;
            margin: 0 auto;
        }
        .container {
            padding: 20px;
        }
        .chat-container {
            border: 1px solid #e0e0e0;
            border-radius: 10px;
            padding: 20px;
            background: #fafafa;
        }
        .control-panel {
            min-width: 250px;
            max-width: 300px;
        }
        .chat-area {
            min-width: 600px;
            flex-grow: 1;
        }
        @media (max-width: 1024px) {
            .control-panel {
                min-width: 200px;
                max-width: 250px;
            }
            .chat-area {
                min-width: 400px;
            }
        }
        @media (max-width: 768px) {
            .control-panel, .chat-area {
                min-width: unset;
                max-width: unset;
                width: 100%;
            }
        }
        """

    def _get_header_markdown(self):
        """è·å–å¤´éƒ¨Markdownå†…å®¹"""
        return """
        # ğŸš€ å¤šæä¾›å•† LLM å®¢æˆ·ç«¯

        ä¸€ä¸ªä¸“ä¸šçš„PCç«¯LLMèŠå¤©å®¢æˆ·ç«¯ï¼Œæ”¯æŒå¤šä¸ªAIæä¾›å•†ã€‚

        **æ”¯æŒçš„æä¾›å•†**: Cerebrasã€DeepSeekã€OpenAI
        **é»˜è®¤æ¨¡å‹**: Qwen-3-235B-A22B-Thinking-2507
        **æ”¯æŒçš„æ¨¡å‹**: Llamaç³»åˆ—ã€Qwenç³»åˆ—ã€DeepSeekç³»åˆ—ã€GPTç³»åˆ—ç­‰
        """

    def _get_initial_status(self):
        """è·å–åˆå§‹çŠ¶æ€ä¿¡æ¯"""
        return api_service.get_provider_status()

    def _setup_event_handlers(
            self, demo, msg, chatbot, model_dropdown,
            submit_btn, clear_btn, export_btn, status_panel
    ):
        """è®¾ç½®äº‹ä»¶å¤„ç†å™¨"""

        def user_message(user_msg, history, model):
            """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
            if not user_msg.strip():
                return "", history

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            self.chat_manager.add_message("user", user_msg)

            # æ›´æ–°Gradioç•Œé¢
            new_history = history + [{"role": "user", "content": user_msg}]
            return "", new_history

        def bot_message(history, model):
            """è·å–æœºå™¨äººå›å¤"""
            if not history:
                return history

            # æ„å»ºAPIæ¶ˆæ¯ - ç›´æ¥ä½¿ç”¨Gradioçš„historyæ ¼å¼
            api_messages = []
            for msg in history:
                if msg["role"] in ["user", "assistant"]:
                    api_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

            # è°ƒç”¨API
            response = api_service.chat_completion(api_messages, model)

            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
            self.chat_manager.add_message("assistant", response)

            # æ›´æ–°Gradioç•Œé¢
            history.append({"role": "assistant", "content": response})
            return history

        def clear_conversation():
            """æ¸…é™¤å¯¹è¯"""
            self.chat_manager.clear_history()
            return [], "å¯¹è¯å·²æ¸…é™¤"

        def export_conversation():
            """å¯¼å‡ºå¯¹è¯"""
            if not self.chat_manager.history:
                return "æ²¡æœ‰å¯¹è¯å†…å®¹å¯å¯¼å‡º"

            export_text = "Cerebras LLM å¯¹è¯è®°å½•\n" + "=" * 50 + "\n"
            for msg in self.chat_manager.history:
                role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
                export_text += f"{role}: {msg['content']}\n\n"

            return export_text

        def update_status():
            """æ›´æ–°çŠ¶æ€ä¿¡æ¯"""
            provider_status = api_service.get_provider_status()
            history_count = self.chat_manager.get_history_length()
            return f"{provider_status} | å¯¹è¯æ•°: {history_count}"

        # ç»‘å®šäº‹ä»¶
        msg.submit(
            user_message,
            [msg, chatbot, model_dropdown],
            [msg, chatbot],
            queue=False
        ).then(
            bot_message,
            [chatbot, model_dropdown],
            [chatbot]
        ).then(
            update_status,
            None,
            [status_panel]
        )

        submit_btn.click(
            user_message,
            [msg, chatbot, model_dropdown],
            [msg, chatbot],
            queue=False
        ).then(
            bot_message,
            [chatbot, model_dropdown],
            [chatbot]
        ).then(
            update_status,
            None,
            [status_panel]
        )

        clear_btn.click(
            clear_conversation,
            None,
            [chatbot, status_panel],
            queue=False
        )

        export_btn.click(
            export_conversation,
            None,
            [status_panel],
            queue=False
        )

        # é¡µé¢åŠ è½½æ—¶æ›´æ–°çŠ¶æ€
        demo.load(update_status, None, status_panel)


def main():
    """ä¸»å‡½æ•°"""
    print("[START] å¯åŠ¨ å¤šæä¾›å•† LLM å®¢æˆ·ç«¯...")

    # æ£€æŸ¥APIé…ç½®
    if not check_api_key():
        print("\nâš ï¸  è¯·å…ˆé…ç½®è‡³å°‘ä¸€ä¸ªAPIå¯†é’¥ç¯å¢ƒå˜é‡")
        print("   åˆ›å»º.envæ–‡ä»¶å¹¶æ·»åŠ ä»¥ä¸‹å˜é‡ä¹‹ä¸€:")
        print("   - CEREBRAS_API_KEY=your_api_key_here")
        print("   - DEEPSEEK_API_KEY=your_api_key_here")
        print("   - OPENAI_API_KEY=your_api_key_here")
        print("\næ‚¨ä»ç„¶å¯ä»¥å¯åŠ¨ç•Œé¢ï¼Œä½†éœ€è¦é…ç½®APIå¯†é’¥æ‰èƒ½æ­£å¸¸ä½¿ç”¨ã€‚")

    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    client = LLMClient()
    demo = client.create_interface()

    # å¯åŠ¨æœåŠ¡å™¨
    demo.launch(
        server_name=SERVER_HOST,
        server_port=SERVER_PORT,
        share=False,
        inbrowser=True,
        show_error=True
    )


if __name__ == "__main__":
    main()
